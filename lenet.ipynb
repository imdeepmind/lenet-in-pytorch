{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = MNIST('./data/mnist',\n",
    "                   download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.Resize((32, 32)),\n",
    "                       transforms.ToTensor()]))\n",
    "data_test = MNIST('./data/mnist',\n",
    "                  train=False,\n",
    "                  download=True,\n",
    "                  transform=transforms.Compose([\n",
    "                      transforms.Resize((32, 32)),\n",
    "                      transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_loader = DataLoader(data_train, batch_size=256, shuffle=True, num_workers=8)\n",
    "data_test_loader = DataLoader(data_test, batch_size=1024, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.cnn_l1 = nn.Conv2d(1, 6, kernel_size=(5,5))\n",
    "        self.cnn_l2 = nn.Conv2d(6, 16, kernel_size=(5,5))\n",
    "        self.cnn_l3 = nn.Conv2d(16, 120, kernel_size=(5,5))\n",
    "        \n",
    "        self.fc_l1 = nn.Linear(48000, 84)\n",
    "        self.fc_l2 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, img):\n",
    "        net = F.relu(self.cnn_l1(img))\n",
    "        net = F.relu(self.cnn_l2(net))\n",
    "        net = F.relu(self.cnn_l3(net))\n",
    " \n",
    "        net = net.view(-1, 48000)\n",
    "        net = F.relu(self.fc_l1(net))\n",
    "        net = F.log_softmax(self.fc_l2(net), dim=1)\n",
    "        \n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (cnn_l1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (cnn_l2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (cnn_l3): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc_l1): Linear(in_features=48000, out_features=84, bias=True)\n",
       "  (fc_l2): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = Network()\n",
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [02:32,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0612, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "235it [02:31,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0430, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "235it [02:35,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0555, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    for i, (images, labels) in tqdm(enumerate(data_train_loader)):\n",
    "        network.zero_grad()\n",
    "        \n",
    "        output = network(images)\n",
    "        \n",
    "        loss = F.nll_loss(output, labels) \n",
    "        \n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        \n",
    "    print(loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:25,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i, (images, labels) in tqdm(enumerate(data_test_loader)):\n",
    "        for j in range(len(images)):\n",
    "            real_class = torch.argmax(labels[j])\n",
    "            net_out = network(images[j].view(-1, 1, 32, 32))\n",
    "            predicted_class = torch.argmax(net_out)\n",
    "\n",
    "            if predicted_class == real_class:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "print(\"Accuracy: \", correct/total*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
